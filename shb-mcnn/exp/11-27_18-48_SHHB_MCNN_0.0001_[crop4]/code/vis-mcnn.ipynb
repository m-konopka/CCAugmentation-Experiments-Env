{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as standard_transforms\n",
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import misc.transforms as own_transforms\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "from misc.utils import *\n",
    "from models.CC import CrowdCounter\n",
    "from config import cfg\n",
    "import CCAugmentation as cca\n",
    "from datasets.SHHB.setting import cfg_data\n",
    "from load_data import CustomDataset\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mean_std = ([0.452016860247, 0.447249650955, 0.431981861591],[0.23242045939, 0.224925786257, 0.221840232611])\n",
    "\n",
    "img_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "restore = standard_transforms.Compose([\n",
    "        own_transforms.DeNormalize(*mean_std),\n",
    "        standard_transforms.ToPILImage()\n",
    "    ])\n",
    "pil_to_tensor = standard_transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './exp/11-26_06-00_SHHB_MCNN_0.0001_[noAug]/all_ep_146_mae_23.91_mse_35.70.pth'\n",
    "model_path = './exp/11-26_06-57_SHHB_MCNN_0.0001_[noAug]/all_ep_175_mae_17.92_mse_26.94.pth'\n",
    "model_path = './exp/11-26_07-42_SHHB_MCNN_0.0001_[noAug]/all_ep_171_mae_18.16_mse_29.66.pth'\n",
    "model_path = './exp/11-27_09-59_SHHB_MCNN_0.0001_[flipLR]/all_ep_180_mae_18.34_mse_30.49.pth'\n",
    "model_path = './exp/11-27_10-44_SHHB_MCNN_0.0001_[flipLR]/all_ep_181_mae_19.11_mse_33.26.pth'\n",
    "# model_path = './exp/11-27_11-30_SHHB_MCNN_0.0001_[flipLR]/all_ep_180_mae_18.16_mse_30.61.pth'\n",
    "\n",
    "net = CrowdCounter(cfg.GPU_ID,cfg.NET)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.cuda()\n",
    "net.eval()              \n",
    "\n",
    "\n",
    "val_pipeline = cca.Pipeline(\n",
    "        cca.examples.loading.SHHLoader(\"/dataset/ShanghaiTech\", \"test\", \"B\"), []\n",
    "    ).execute_generate()\n",
    "val_loader = DataLoader(CustomDataset(val_pipeline), batch_size=cfg_data.VAL_BATCH_SIZE, num_workers=1, drop_last=False)\n",
    "\n",
    "val_img = list(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "N = 3\n",
    "\n",
    "for vi, data in enumerate(val_img[start:start+N], 0):\n",
    "    img, gt_map = data\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = Variable(img).cuda()\n",
    "        pred_map = net.test_forward(img)\n",
    "        pred_map = pred_map.data.cpu().numpy()\n",
    "        \n",
    "    new_img = img.data.cpu().numpy()\n",
    "    new_img = np.moveaxis(new_img, 1, 2)\n",
    "    new_img = np.moveaxis(new_img, 2, 3)\n",
    "    new_img = np.squeeze(new_img)[:,:,::-1]\n",
    "    \n",
    "    pred_cnt = np.sum(pred_map[0])/100.0\n",
    "    gt_count = np.sum(gt_map.data.cpu().numpy())/100.0\n",
    "    \n",
    "    fg, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    plt.suptitle(' '.join([\n",
    "            'count_label:', str(round(gt_count, 3)),\n",
    "            'count_prediction:', str(round(pred_cnt, 3))\n",
    "        ]))\n",
    "    ax0.imshow(np.uint8(new_img))\n",
    "    ax1.imshow(np.squeeze(gt_map), cmap='jet')\n",
    "    ax2.imshow(np.squeeze(pred_map), cmap='jet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.empty(len(val_img))\n",
    "mse = np.empty(len(val_img))\n",
    "for vi, data in enumerate(tqdm(val_img), 0):\n",
    "    img, gt_map = data\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = Variable(img).cuda()\n",
    "        pred_map = net.test_forward(img)\n",
    "        pred_map = pred_map.data.cpu().numpy()\n",
    "    \n",
    "    pred_cnt = np.sum(pred_map[0])/100.0\n",
    "    gt_count = np.sum(gt_map.data.cpu().numpy())/100.0\n",
    "    mae[vi] = np.abs(gt_count-pred_cnt)\n",
    "    mse[vi] = (gt_count-pred_cnt)**2\n",
    "    \n",
    "print('MAE:', round(mae.mean(),2))\n",
    "print('MSE:', round(np.sqrt(mse.mean()),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
